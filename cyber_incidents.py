# -*- coding: utf-8 -*-
"""20212425023_Mustafa-Cuneyt-Kafes_Cyber-Incidents-Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MqhBnNfLDh3EcJglZsGzS_XtuxQVPmoM

# **2005-2020 Yılları Arasında Gerçekleşen Siber Olaylar**

Bu projede, 2005-2020 yılları arasında gerçekleşen gerçek siber olayların belirli bir kısmınının kaydedildiği dataset'teki veriler incelenmiştir. Veriler grafik halinde görselleştirilerek raporlanma sağlanmış, bir sonraki yılda gerçekleşebilecek olan saldırıların tahmini yapılmaya çalışılmıştır.

Veri işleme ve görselleştirme kısımlarında matlab, pandas, numpy, seaborn, wordcloud kütüphaneleri, veri tahmin aşamasında yapay zekayı desteklemek için sklearn ve csv kütüphaneleri kullanılmıştır.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from wordcloud import WordCloud, STOPWORDS

import numpy as np

import csv

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor

"""## **Veriye ilk bakış**

Bu aşamada verilerin yer aldığı csv formatındaki dataset dosyası okunarak, işlemlere başlamadan önce verileri anlamak ve anlamlandırmak amaçlanmıştır.
"""

df = pd.read_csv('/content/drive/MyDrive/cyber-operations-incidents.csv')

df.head() # veri setimizdeki ilk 5 satırı listeliyoruz

"""Veri setindeki sütunların kontrolünü sağlamak için `df.info()` komutu kullanılmıştır.

"""

df.info() # veri setimizdeki sütunların kontrolünü sağlıyoruz

"""Veri setinde boş değerlerin olup olmadığı hakkında bilgi sağlayabilmek için `df.isnull().values.any()` komutu kullanılmıştır. Eğer veride bilgi içermeyen kısımlar varsa, bu boş değerlerin sayısına ulaşmak için `df.isnull().sum()` komutu kullanılacaktır."""

df.isnull().values.any() # verilerde boşluk var mı ?

df.isnull().sum() # hangi sütunlarda ne kadar boşluk var

"""### **WordCloud**

Bu aşamada, wordcloud yapısını kullanarak sahip olduğumuz tüm veriler arasında en çok bulunan kelimeler görüntülenmiş, Verilerin içeriği hakkında genel bir bilginin tablo olarak sunulması amaçlanmıştır.
"""

word_string = " ".join(df["Description"].str.lower()) # description sütunundaki verileri küçük karakter formatında birleştiriyoruz
wordcloud = WordCloud(stopwords=STOPWORDS, colormap='winter', background_color="white").generate(word_string) # wordcloud oluşturma kodu

fig, ax = plt.subplots(1, 1, figsize=(8, 8))
plt.clf()
plt.imshow(wordcloud)
plt.axis('off')
plt.title('Word Cloud (Tüm Veriler)', fontsize=18, c='black')
plt.show()

"""## **Veri İnceleme**

Bu aşamada veriler görselleştirilerek, genelden özele doğru bir inceleme yapılmıştır. Bilgilerin görselleştirilme kısmında pasta grafiği (pie), sütun grafiği (barh ve bar plot), çizgi grafiği (line plot), saçılım grafiği (scatter plot) kullanılmıştır.
"""

# Pasta grafiği
ax = df['Type'].value_counts().plot.pie(figsize=(6, 5), autopct='%1.1f%%', wedgeprops={'linewidth': 2.0, 'edgecolor': 'white'}, textprops={'size': 'x-large'})

"""Veri setinde yer alan; 2005-2020 Yılları arasında gerçekleşen saldırı türlerinin sayısı görselleştirilmiştir.

```
Espionage           = Casusluk      (Gizli bilgileri bulma veya bir işlemi takip etme)
Sabotage            = Sabotaj       (Korku veya caydırma amacı içeren saldırılar)
Denial of Service   = Servis Reddi  (Sunucu Çökertme)
Data Destruction    = Veri İmhası
Financial Theft     = Finansal Hırsızlık
Doxing              = Gizli Bilgileri Bulup Yayma
Defacement          = Arayüz Görünümünü Değiştirme Saldırıları
```
"""

saldiri_turleri = df['Type'].value_counts().index # saldırı türlerini değişkene alıyoruz

fig, ax = plt.subplots(1, 1, figsize=(11, 3)) # plot grafik oluşturuyoruz
sns.countplot(data=df, x='Type', order=saldiri_turleri, palette='Spectral') # veriyi tabloya yerleştirerek renk ayarlaması yapıyoruz

ax.set(xlabel='Saldırı Türleri') # alt kısım için yazı
ax.set(ylabel='Saldırı Sayısı') # sol kısım için yazı

plt.title('2005-2020 Yılları Arasında Gerçekleşen Saldırı Türlerinin Sayısı', fontsize=16, c='black') # grafik başlığı
plt.show()

"""## **Veri Filtreleme**

Bu aşamada veriler tarih, ülke ismi gibi spesifik kriterlere göre incelenerek görselleştirilmiştir.
"""

while True:
    girilen_yil = input("2005-2020 arasında bir tarih giriniz: ")
    try:
        girilen_yil = int(girilen_yil)
    except Exception as e:
        print(f"Hata!\n{e.args}")
        continue
    if 2005 <= girilen_yil <= 2020:
        girilen_yil = str(girilen_yil)
        break
    else:
        print("Geçersiz tarih girdiniz")

baslangic_tarihi = girilen_yil+'-01-01'
bitis_tarihi = girilen_yil+'-12-31'

"""Date sütununda yer alan tarih verilerinin pandas kütüphanesi tarafından "tarih" olarak görülebilmesi ve bazı özel fonksiyonların kullanılabilmesi için "datetime" objesine dönüştürülmesi gerekmektedir.

Date sütununda yer alan veriler pandas'ta bulunan "datetime" objesine çevrilmiştir. Date kısmı boş olan satırlar ise veri setinden silinmiştir.
"""

df["Date"] = pd.to_datetime(df["Date"])  # pandas datetime objesine çeviriyoruz (sort fonksiyonu vs. çalışması için)
df_yillar = df[pd.notnull(df['Date'])] # Date kısmı boş olan satırların silinmesini sağlıyoruz

"""Seçilen yıl ile ilgili veri setinde filtreleme işlemi aşağıdaki kod bloğunda yer almaktadır."""

yil_verileri = (df_yillar['Date'] > baslangic_tarihi) & (df_yillar['Date'] <= bitis_tarihi) # başlangıç ve bitiş tarihi aralığındaki tarihleri alıyorum
yil_verileri = df_yillar.loc[yil_verileri] # string değer olduğu için loc kullanıldı | yil_verileri sorgusuna göre verileri getir
yil_verileri = yil_verileri.reset_index(drop=True)
yil_verileri = yil_verileri.drop(['Sources_1', 'Sources_2', 'Sources_3'], axis=1) # siber olaylarla ilgili kaynaklara ihtiyaç duymadığımız için bu verileri siliyoruz

"""Aşağıda seçilen tarihteki wordcloud verisi görselleştirilerek, ilgili tarihteki verilere genel bir bakış atmak amaçlanmıştır."""

word_string = " ".join(yil_verileri['Description'].str.lower())
wordcloud = WordCloud(stopwords=STOPWORDS, colormap='winter', background_color="white").generate(word_string)

fig, ax = plt.subplots(1, 1, figsize=(8, 8))
plt.clf()
plt.imshow(wordcloud)

plt.axis('off')
plt.title(f'Word Cloud ({girilen_yil} Yılındaki Veriler)', fontsize=18, c='black')
plt.show()

"""Aşağıda seçilen tarihteki tehdit aktörleri listelenmiştir."""

siber_olaylar_yil = yil_verileri["Affiliations"].value_counts()

fig, ax = plt.subplots(1, 1, figsize=(8, 9)) # plot grafik oluşturuyorum
sns.countplot(data=yil_verileri, y='Affiliations', order=yil_verileri["Affiliations"].value_counts().index, palette="Spectral") # datayı tabloya yerleştiriyorum, renk ayarlaması yapıyorum

ax.set(xlabel='Saldırı Sayıları') # alt kısım için yazı
ax.set(ylabel='Tehdit Aktörleri') # sol kısım için yazı
plt.title(f'{girilen_yil} Yılındaki Tehdit Aktörleri', fontsize=16, c='black')
plt.subplots_adjust(left=0.56, right=0.97)
plt.show()

"""Aşağıda seçilen tarihteki saldırılara en çok sponsor olan tüzel kişiler listelenmiştir."""

fig, ax = plt.subplots(1, 1, figsize=(6, 4))
sns.countplot(data=yil_verileri, y='Sponsor', order=yil_verileri["Sponsor"].value_counts().index, palette='Blues') # (alternatif: palette='mako')

ax.set(xlabel='Saldırı Sayıları') # alt kısım için yazı
ax.set(ylabel='Sponsorlar') # sol kısım için yazı

plt.title(f'{girilen_yil} Yılındaki Saldırılara En Çok Sponsor Olanlar', fontsize=16, c='black')
plt.subplots_adjust(left=0.25)
plt.show()

"""Aşağıda yer alan kod bloğunda seçilen ülkenin yıllara göre siber saldırıya maruz kalma sayısını görebilmek amaçlanmıştır."""

secilen_ulke = input("Lütfen ülkenin tam ismini giriniz: ")
ulke_kisaltmasi = input("Lütfen ülkenin kısaltmasını giriniz: ")

ulkedeki_veriler = df[df["Victims"].astype(str).str.contains('|'.join([secilen_ulke, ulke_kisaltmasi]), case=False)]
yila_gore_hacklenme = ulkedeki_veriler.groupby([df["Date"].dt.year]).agg({'Type': 'count'})

yila_gore_hacklenme.plot(style="-o", figsize=(6, 4), title=f"Yıllara Göre Maruz Kalınan Siber Saldırı Sayısı ({secilen_ulke})")

"""## **Veri Tahmini**

Bu aşamada veri tahminini gerçekleştirmek üzere yapay zekanın performansını artırmak istenmiş, buna bağlı olarak regresyon işlemi uygulanmıştır.

**Regresyon nedir ?**

Regresyon denklemi birden fazla değişken arasındaki ilişkiyi analiz etmeye ve buna bağlı olarak yeni tahminler üretilebilmesine olanak sağlar.

2020 yılındaki "Defacement" (arayüz görünümünü değiştirme) saldırısına yönelik verileri hesaplamak için kalan saldırı türleri bağımsız değişken olarak kabul edilir ve bu veriler kullanılarak bir regrasyon denklemi oluşturulur.

bu sayede "Defacement" sayısı 2020 yılı için tahmin edilir. Ardından 2020 yılındaki gerçek değer ile arasındaki fark incelenir ve MSE , RMSE değerleri bulunur. Bu işlem bağımsız değişkenlere olduğu sürece her yılda tahmin yapmak için kullanılabilir.

```
MSE = ortalama hatanın karesi
RMSE = ortalama karekök sapması
```

Kısaca özetlemek gerekirse; 2021 yılındaki verileri tahmin etmek istiyorsak öncelikle elimizde var olan değerleri tahmin etmemiz ve program ne kadar hata veriyor onu tespit etmemiz gerekir. Hata payını en aza indirdikten sonra gelecek yılları tahmin etmek daha kolay olacaktır.

Gelecek yıl "Defacement" arayüz saldırısının ne kadar olacağını tahmin edebilmek için kullanacağımız regrasyon denkleminde ihtiyaç duyduğumuz şey hangi yıl hangi saldırıların ne kadar olduğudur. Bu yüzden aşağıdaki kod bloğunda sahip olunan verilerle yeni bir CSV dosyası yaratılmıştır.
"""

fields = list(df['Type'].value_counts().index)
fields.insert(0, "Year")
rows = []

for year in range(2005, 2021):
    baslangic_tarihi = f'{year}-01-01'
    bitis_tarihi = f'{year}-12-31'

    yil_verileri = (df_yillar['Date'] > baslangic_tarihi) & (df_yillar['Date'] <= bitis_tarihi) # başlangıç ve bitiş tarihi aralığındaki tarihleri alıyorum
    yil_verileri = df_yillar.loc[yil_verileri] # string değer olduğu için loc kullanıldı | yil_verileri sorgusuna göre verileri getir

    year_fields = list(yil_verileri["Type"].value_counts().index)
    year_rows = list(yil_verileri["Type"].value_counts().reset_index(name="count")["count"])
    year_output = list(zip(year_fields, year_rows))

    result = [0]*len(fields) # [0, 0, 0, 0, 0, 0, 0]
    result[0] = year # [2007, 0, 0, 0, 0, 0, 0]
    
    for i,f in enumerate(fields):
        for yf in year_output:
            if f == yf[0]:
                result[i] = yf[1]

    rows.append(result)

# CSV dosyamızın görüntüsü
print(fields)
for e in rows:
  print(e)

# dosya yazma işlemi
with open('predictdata.csv', 'w') as f:
    write = csv.writer(f)
    write.writerow(fields)
    write.writerows(rows)

"""Oluşturulan predictdata isimli csv dosyasını olarak okuma işlemi yapılmıştır. Makine öğrenmesi modelini beslemek üzere X_train, y_train, X_test ve y_test değişkenleri oluşturulmuştur.

X_train = 2005-2019 arasındaki saldırı türleri

y_train = 2005-2019 arasındaki "defacement" saldırı değeri

x_test = 2020 yılındaki saldırı türleri

y_test = 2020 yılındaki "defacement" saldırı değeri
"""

predictdata = pd.read_csv('predictdata.csv')
X_train = predictdata.iloc[:15, 1:7] # 2005-2019 arası diğer saldırı türleri
y_train = predictdata.iloc[:15, 7] # 2005-2019 arası "defacement" saldırı değerleri
X_test = predictdata.iloc[15:16, 1:7] # 2020 yılındaki diğer saldırı türleri
y_test = predictdata.iloc[15:16, 7] # 2020 yılındaki "defacement" saldırı değeri

(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

"""#### **MULTIPLE LINEAR REGRESSION**

Modelin toplanan veriye ne kadar uyum gösterdiğini bulmak üzere 2005-2019 arasındaki bütün verilerimi fit fonksiyonuna gönderiyoruz.

2020 yılındaki saldırı türlerini vererek 2020 yılındaki defacement saldırısını tahmin etmek için predict(tahmin) fonksiyonunu kullanıyoruz.

MSE ve RMSE değerlerine erişerek programın efektifliğini ölçüyoruz.
"""

reg = LinearRegression()

reg.fit(X_train, y_train) # 2005-2019 arasındaki tüm veriler

y_pred_linear = reg.predict(X_test) # 2020 yılındaki diğer saldırı türlerini vererek, 2020 yılındaki defacement saldırısını tahmin etmesini istiyoruz


# tahmin edilen değer ile gerçek değer arasındaki hata payını buluyoruz
mse_linear = mean_squared_error(y_test, y_pred_linear)
rmse_linear = np.sqrt(mse_linear)


# MSE = ortalama hata karesi
# RMSE = ortalama hatanın karekökü

print(f"MSE: {mse_linear}\nRMSE: {rmse_linear}")

types = list(df['Type'].value_counts().index) # saldırı türleri

data_2021 = [0]*len(types) # [0, 0, 0, 0, 0, 0, 0]
data_2021[0] = "2021"

for i, type in enumerate(types):
    #sadece 1 satır için tahmin işlemi yapacağız, bu yüzden reshape kullanıyoruz
    X = predictdata["Year"].values.reshape(-1, 1)
    #saldırı türünün değerlerini kullanarak bir sonraki değerini tahmin etmeye çalışacağız 
    y = predictdata[str(type)].values

    model = LinearRegression()
    model.fit(X, y)

    #tahmin işlemi için predict fonksiyonunun kullanarak 2021 yılındaki veriyi tahmin etmeye çalışıyoruz
    prediction_2021 = model.predict([[2021]])
    #çıkan sonucu saldırı türünün id'sine göre listeye ekliyoruz
    data_2021[i] = prediction_2021[0]

data_2021

data2 = {"Types": types,
         "2021": data_2021}

df3 = pd.DataFrame(data2)

print(df3)

"""Aşağıdaki grafikte 2005-2020 yılları arasında gerçekleşmiş saldırıların türlere göre sayıları gösterilmiştir."""

predictdata.set_index("Year").plot(grid=True, figsize=(8, 3))

"""Aşağıdaki grafikte ise 2021 yılı için makine öğrenmesi ile geliştirmiş olduğumuz algoritmanın tahmin ettiği, saldırı türlerine ait sayılar yer almaktadır."""

sns.lineplot(x=df3.head()["Types"], y=df3.head()["2021"], sizes=(3, 3))
sns.set(rc={'figure.figsize': (10, 5)})
